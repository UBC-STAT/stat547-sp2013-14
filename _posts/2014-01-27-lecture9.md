---
layout: post
title: "Lecture 9: Point and jump processes continued"
category: 'Lecture'
---

Instructor: Alexandre Bouchard-C&ocirc;t&eacute;

Editor: TBA


### Point process, continued

#### Application 2: Creating a Bayesian non-parametric prior over *infinite latent features*

**Motivation:** modelling customer choices via latent features.

Given a finite set of types of products (e.g. laptop, cellphone, etc.) and a finite number of choices for each, you ask people questions of the form 'you you buy an android or an iphone?'. 

What we can do so far: cluster people, e.g. 'thrifty people' vs. 'extravagant'. Problem: one can imagine other useful clustering that are overlapping, e.g. 'people in their 0-19', '20-29', '30-39', '40+'. The problem is that we did not take note or have access to these  (e.g. because of privacy). These are then called *latent features*.

Idea: instead of assigning each datapoint (person interviewed) exactly one $\theta$, let us assign them a set of thetas, $\\{\theta\\}$. 

Given the $\\{\theta\\}$ we can easily build a parametric model over choices (e.g. with GLM machinery).

Matrix picture.

**Beta process:** Instead of an infinite list of sticks that sum to one, we want an infinite list of stick each between zero and one, but that do not need to sum to one. (can you see the difference with the gamma process?)

Then each customer flips a coin for each stick, with the bias given by the height of the stick. This specifies whether the customer picks the corresponding dish $\theta$. We want the probabilities to decay fast enough to guarantee that only a finite number of dishes are picked by each customer (but not too fast, so that the number of dishes used across all customers always grows).

It turns out it is possible to construct such random list by simply modifying the Levy measure into:

\begin{eqnarray}
y^{-1} (1-y)^{c} p(x),
\end{eqnarray}

where $c$ is a positive constant hyper-parameter.

With this choice, much of the machinery we have developed in the DP case can be also developed for this new process. See [Miller 2011](http://ai.stanford.edu/~tadayuki/papers/miller-phd-dissertation11.pdf) for detail, here we will only cover the highlight:

**Indian Buffet Process (IBP):** an exchangeable distribution over the sampled sets $\underline{\\{\theta\_i\\}}$, which is to the beta process what the CPR is to the DP:

1. The first customer picks a Poisson distributed number of dishes, with parameter $c$.
2. Customer $n+1$ does the following:
   - Look at each dish that was picked more than once before. For each one, if $i \ge 1$ is the number of times it has been taken before, take it as well independently with probability $i/(c+n)$.
   - Pick a Poisson distributed number of new dish, with rate parameter $c/n$.

#### Application 3: Other normalized completely random measures

Interestingly, the PY process cannot be constructed this way (by normalizing a CRM). However, other normalized CRMs offer interesting generalization to Dirichlet processes.

An important example is the **Generalized Gamma CRM**, with Levy measure given by:

\begin{eqnarray}
\frac{a}{\Gamma(1-\sigma)} y^{-\sigma - 1} e^{-\tau y} p(x),
\end{eqnarray}

where $a > 0$, $\sigma \in (0,1)$ and $\tau \ge 0$ are hyper-parameters.

See [Favaro and Teh, 2013](http://www.stats.ox.ac.uk/~teh/research/npbayes/FavTeh2013a.pdf).

**Note:** Research project examples.

- Urban statistics and MGP.
- What happens if you multiply a Gamma r.v. with a PY?

### Jump processes

**Notation:** Let $S$ denote a finite set of *states*. In this lecture, we will study processes $Y\_t$ indexed on the real line $t \in [0, \infty)$, and taking values in $S$.

**Assumption:** We will be making the following Markov assumption: for all states $x\_n$ and times $t\_1 < t\_2 < \dots < t\_n$, we assume that

\begin{eqnarray}
\P(X\_{t\_n} = x\_n | X\_{t\_1} = x\_1, \dots, X\_{t\_{n-1}} = x\_{n-1}) = \P(X\_{t\_n} = x\_n | X\_{t\_{n-1}} = x\_{n-1}).
\end{eqnarray}

**Examples/applications:**

- DNA example from first assignment
- Survival analysis
- Queueing theory
- Switching state/anomaly detection

**Recall: simulation from a CTMC (lecture 1):**

1. Initialize $y = y_0$, $p = ()$ to an empty list.
2. Repeat:
   1. Simulate a waiting time: use an exponential distribution with the rate corresponding to the current state, $\Delta t \sim \Exp(\lambda\_y)$.
   2. Add a new segment to the piecewise constant path: $p \gets p \circ (y, \Delta t)$, where $\circ$ denotes concatenation (i.e. we represent a path with a list of pair, where each pair has the length of a segment, $\Delta t$, and its state $y$).
   3. Simulate a transition: use a categorical distribution with the probabilities given by row $y$ of the transition matrix, $y' \sim \Cat(M(y,\cdot))$.
   4. Update the current state: $y \gets y'$
   
#### Why Markov assumption implies we can use this simple generative process

**Short answer: Memorylessness.** 

**Recall:** A random variable $T$ is memoryless is

\begin{eqnarray}
\P(T > t + s | T > s) = P(T > t).
\end{eqnarray}

**Recall:** the exponential distribution is the only continuous memoryless distribution.

**Proposition:** homogeneous, finite state Markov chains can be simulated using the algorithm from lecture 1.

**Proof:** Suppose $X\_0 = x$, and denote the time to the first jump by $T\_x$. It is enough to show that $T\_x$ is memoryless:

\begin{eqnarray}
\P(T\_x > s + t | T\_x > s) &=& \P(X\_r = x \textrm{ for }r\in[0, s+t] | X\_r = x \textrm{ for }r \in [0,s]) \\\\
&=& \P(X\_r = x \textrm{ for }r\in[s, s+t] | X\_r = x \textrm{ for }r \in [0,s]) \\\\
&=& \P(X\_r = x \textrm{ for }r\in[s, s+t] | X\_s = x ) \textrm{ (Markov assumption) } \\\\
&=& \P(X\_r = x \textrm{ for }r\in[0, t] | X\_0 = x ) \textrm{ (homogeneity assumption) }\\\\
&=& \P(T\_x > t).
\end{eqnarray}
   
#### Estimation of CTMCs: full observation

In the simplest case, assume that 



- matrix exponentiation

- likelihood

- paper of Teh



### Supplementary references and notes

**Under construction**
