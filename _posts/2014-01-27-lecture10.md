---
layout: post
title: "Lecture 10: Jump and diffusion processes"
category: 'Lecture'
---

Instructor: Alexandre Bouchard-C&ocirc;t&eacute;

Editor: TBA


### Jump processes, continued

#### Review from last time: computing the matrix exponential.

**Why?** A tool needed for MCMC approximation to the posterior over $Q$ given *partial* observations.

**What is the interpretation?** An end-point conditioned probability, $\P(X\_t = y | X\_0 = x)$, marginalizing over all possible paths. Result organized into a matrix where rows are $x$ indices and columns are $y$ indices.

**What is the definition?** Same Taylor series as standard exponential, with a matrix argument instead.

\begin{eqnarray}
P\_t &=& \exp(tQ) \\\\
\exp(M) &=& \sum\_{n=0}^\infty \frac{M^n}{n!}.
\end{eqnarray}

**How to compute it in practice?** Suppose $Q$ an be diagonalized, $A = U D U^{-1}$, $D = \textrm{diag}(\lambda\_i)$.

Write:

\begin{eqnarray}
\exp(tQ) &=& U U^{-1} + U (tD) U^{-1} + \frac{1}{2!} U(tD) U^{-1} U (tD) U^{-1} + \dots \\\\
&=& U (I + (tD) + \frac{1}{2!} (tD)^2 + \dots) U^{-1} \\\\
&=& U \textrm{diag}(\exp(t \lambda\_i)) U^{-1}
\end{eqnarray}

**Consequence:** One simple way of getting the stationary distribution:

\begin{eqnarray}
\lim\_{t\to\infty} \P(X\_t = x | X\_0) &=& \lim\_{n \to \infty} \P(X\_n = x | X\_0 = y) \\\\
\lim\_{n\to\infty} ((\P\_1)^n)\_{x,y}
\end{eqnarray}



**Application:** Bayesian phylogenetics.

**ML, EM, and uniformization**



<!-- - matrix exponential

- MH case

- uniformization

- method of Teh

- ML


- reversibility Often it is convenient to assume that the $\mu = \pi$, the stationary distribution (to be 


- matrix exponentiation

- likelihood

- paper of Teh

-->

**Notation:** Let $S$ denote a finite set of *states*. In this lecture, we will study processes $Y\_t$ indexed on the real line $t \in [0, \infty)$, and taking values in $S$.

**Assumption:** We will be making the following Markov assumption: for all states $x\_n$ and times $t\_1 < t\_2 < \dots < t\_n$, we assume that

\begin{eqnarray}
\P(X\_{t\_n} = x\_n | X\_{t\_1} = x\_1, \dots, X\_{t\_{n-1}} = x\_{n-1}) = \P(X\_{t\_n} = x\_n | X\_{t\_{n-1}} = x\_{n-1}).
\end{eqnarray}

**Examples/applications:**

- DNA example from first assignment
- Survival analysis
- Queueing theory
- Switching state/anomaly detection

Note: CTMC naturally handle all types of observation (full, partial/censored, unequally spaced, etc).

**Recall: simulation from a CTMC (lecture 1):**

1. Initialize $y = y_0$, $p = ()$ to an empty list.
2. Repeat:
   1. Simulate a waiting time: use an exponential distribution with the rate corresponding to the current state, $\Delta t \sim \Exp(\lambda\_y)$.
   2. Add a new segment to the piecewise constant path: $p \gets p \circ (y, \Delta t)$, where $\circ$ denotes concatenation (i.e. we represent a path with a list of pair, where each pair has the length of a segment, $\Delta t$, and its state $y$).
   3. Simulate a transition: use a categorical distribution with the probabilities given by row $y$ of the transition matrix, $y' \sim \Cat(M(y,\cdot))$.
   4. Update the current state: $y \gets y'$
   
#### Why Markov assumption implies we can use this simple generative process

**Short answer: Memorylessness.** 

**Recall:** A random variable $T$ is memoryless if

\begin{eqnarray}
\P(T > t + s | T > s) = \P(T > t),
\end{eqnarray}

or equivalently:

\begin{eqnarray}
\P(T > t + s) = \P(T > t) \P(T > s).
\end{eqnarray}

**Recall:** the exponential distribution is the only continuous memoryless distribution. In other words, $P\_t = \P(T > t)$ is continuous with $P\_0 = 1$ and $P\_{t+s} = P\_t P\_s$, iff $P\_t = e^{-\lambda x}.$

**Proposition:** homogeneous, finite state Markov chains can be simulated using the algorithm from lecture 1.

**Proof:** Suppose $X\_0 = x$, and denote the time to the first jump by $T\_x$. It is enough to show that $T\_x$ is memoryless:

\begin{eqnarray}
\P(T\_x > s + t | T\_x > s) &=& \P(X\_r = x \textrm{ for }r\in[0, s+t] | X\_r = x \textrm{ for }r \in [0,s]) \\\\
&=& \P(X\_r = x \textrm{ for }r\in[s, s+t] | X\_r = x \textrm{ for }r \in [0,s]) \\\\
&=& \P(X\_r = x \textrm{ for }r\in[s, s+t] | X\_s = x ) \textrm{ (Markov assumption) } \\\\
&=& \P(X\_r = x \textrm{ for }r\in[0, t] | X\_0 = x ) \textrm{ (homogeneity assumption) }\\\\
&=& \P(T\_x > t).
\end{eqnarray}
   
#### Estimation of CTMCs: fully observed case

Assume first that the full path can be observed. We will relax this assumption later. Suppose also that we observe a single time series, with times holding times $(t\_1, t\_2, t\_3)$ and states  $(x\_1, x\_2, x\_3)$. Suppose also that the pmf of the initial distribution is $\mu$. 

**Bayesian way:** one could put gamma priors on the $\lambda$s and Dirichlet priors on the $M$s. This yields a simple conjugate family. (But see [Ferreira and Suchard](http://faculty.biomath.ucla.edu/msuchard/publications/papers/Ferreira-inpress-CJS.pdf) for other, more robust choices of priors based on conditional reference prior, which exhibit better frequentist coverage properties.)

**Maximum likelihood:** The likelihood for fully observed sequences is:

\begin{eqnarray}
\mu(x\_1) \left( \lambda(x\_1) e^{-t\_1 \lambda(x\_1)} M(x\_1, x\_2) \right) \times \left( \lambda(x\_2) e^{-t\_2 \lambda(x\_2)} M(x\_2, x\_3) \right) \times e^{-t\_3 \lambda(x\_3)}
\end{eqnarray}

**Note 1:** why is the last factor different?

**Note 2:** as you saw in the first assignment (and will be discussed in more details today or next lecture), $\lambda$ and $M$ can be reparameterized into a rate matrix $Q = (q\_{i,j})$ as follows:

\begin{eqnarray}
\lambda(x) &=& -q\_{x,x}, \\\\
M(x, x') &=& \frac{q\_{x, x'}}{-q\_{x, x}},
\end{eqnarray}

obtaining:

\begin{eqnarray}
\mu(x\_1)  \left( e^{-t\_1 q\_{x\_1}} q\_{x\_1, x\_2} \right) \times \left(  e^{-t\_2 q\_{x\_2}} q\_{x\_2, x\_3} \right) \times e^{-t\_3 q\_{x\_3}}
\end{eqnarray}

**Note 3:** Finally, the terms can be grouped, revealing that the total time spent at each state, $T(x)$, and the number of transitions between each pair of states $N(x, x')$, are sufficient statistics:

\begin{eqnarray}
\mu(x\_1)  \prod\_x e^{- q\_{x,x\} T(x)} \prod\_{x' \neq x} q\_{x, x'}^{N(x, x')}.
\end{eqnarray}

Maximizing the log likelihood with the constraint that $- q\_{x,x\} = \sum\_{x' \neq x} q\_{x, x'}$ is then straightforward (see [Hobolth and Yoshida, 2005](http://arxiv.org/abs/q-bio/0511034)). 

#### Estimation of CTMCs: partially observed case

Suppose now that we only observe the end-points $x,y$ of one (or several) time series. Suppose that the time between the observation $t$ is also known. We need to marginalize over the intermediate paths, $\P\_q(X\_0 = x, X\_t = y) = \mu\_q(x) \P\_q(X\_t = y | X\_0 = x)$ (maximizing over them leads to a degenerate solution, see [Perkins, 2009](http://books.nips.cc/papers/files/nips22/NIPS2009_0822.pdf)). Here the $q$ subscript denotes the dependence of the marginal probabilities on the rate matrix $Q$ we are optimizing over.

The main tool we will cover here is the *matrix exponential*, which allows us to do the marginalization analytically. 

Note that once we can compute $\P\_q(X\_t = y | X\_0 = x)$, it is straightforward to design a MH sampler: let $p(q)$ denote a prior density on the entries of $q$. Given a proposal on $q$ with density $\rho$, we accept a new value $q'$ by calculating the ratio:

\begin{eqnarray}
\frac{p(q')}{p(q)} \frac{\P\_{q'}(X\_t = y | X\_0 = x)}{\P\_q(X\_t = y | X\_0 = x)} \frac{\rho(q | q')}{\rho(q' | q)}.
\end{eqnarray}

**Review/background: How to compute the marginal?**

Let $(P\_t)\_{i,j} = \P(X\_t = j | X\_0 = i)$. What do we know about this matrix valued function $P\_t$?

1. $P\_0 = I$
2. Kolmogorov consistency: $(P\_t)\_{i,j} = \sum\_k (P\_t)_{i,k} (P\_t)\_{k,j}$

**Note:** how do we write this in vector notation?

**Compare to earlier discussion on memorylessness:** Extension: (1) and (2) hold iff $Q$ such that 

\begin{eqnarray}
P\_t &=& \exp(tQ) \\\\
\exp(M) &=& \sum\_{n=0}^\infty \frac{M^n}{n!}.
\end{eqnarray}

We will see next lecture $Q$ is actually the same as the $Q$ used in the generative process, just as the name suggests.

**Computing the matrix exponential:**

Suppose $Q$ an be diagonalized, $A = U D U^{-1}$, $D = \textrm{diag}(\lambda\_i)$.

Write:

\begin{eqnarray}
\exp(tQ) &=& U U^{-1} + U (tD) U^{-1} + \frac{1}{2!} U(tD) U^{-1} U (tD) U^{-1} + \dots \\\\
&=& U (I + (tD) + \frac{1}{2!} (tD)^2 + \dots) U^{-1} \\\\
&=& U \textrm{diag}(\exp(t \lambda\_i)) U^{-1}
\end{eqnarray}

**Consequence:** One simple way of getting the stationary distribution:

\begin{eqnarray}
\lim\_{t\to\infty} \P(X\_t = x | X\_0) &=& \lim\_{n \to \infty} \P(X\_n = x | X\_0 = y) \\\\
\lim\_{n\to\infty} ((\P\_1)^n)\_{x,y}
\end{eqnarray}

**Application:** Bayesian phylogenetics.

**ML, EM, and uniformization**



<!-- - matrix exponential

- MH case

- uniformization

- method of Teh

- ML


- reversibility Often it is convenient to assume that the $\mu = \pi$, the stationary distribution (to be 


- matrix exponentiation

- likelihood

- paper of Teh

-->

### Supplementary references and notes

**Under construction**
